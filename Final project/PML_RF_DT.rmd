---
title: "Practical Machine Learning - Course Project"
author: "Udaya Bhaskar K"
date: "Saturday, January 24, 2015"
output: html_document
---

**Background Introduction:** 

This particular project contains files which were written and tested in according to the project requirements as mentioned below.
"
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset)."
 

```{r}
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)

# setting seed value for enabling reproducability. 
set.seed(12345)


# Getting the data The training data set can be found on the following URL:

training = read.csv("pml-training.csv", header=T, na.strings=c("NA","#DIV/0!",""))
testing = read.csv("pml-testing.csv", header=T, na.strings=c("NA","#DIV/0!",""))

# Sub Splitting the Training data into training and testing in 70% and 30% each reply

partTrain = createDataPartition(y=training$classe, p=0.7, list=FALSE)
myTraining = training[partTrain, ]
myTesting = training[-partTrain, ]
dim(myTraining) 
dim(myTesting)
```

Now if you can look at the dataset that we downloaded we can observe that many of the values are missing and NAs so we have to preprocess the dataset to have a cleaned data for better ML performance. 

```{r}
### Cleaning the data 

## Cleaning Step - I 
# first cleaning all the near zero or no value variables in the data sets
# This was done by checking all the variables which have no value and 
# removed using the below code. 

NearZeroVar = names(myTraining) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt", "kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt", "max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm", "var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm", "stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm", "kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
"max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm", "kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
"skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",  "amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm", "skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm", "max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm", "amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
"avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm", "stddev_yaw_forearm","var_yaw_forearm")

myTraining = myTraining[!NearZeroVar]

#To check the new dimensions of observations
dim(myTraining)

## Cleaning Step - II
# removing the first column that contains the person id
myTraining = myTraining[c(-1)]

## Cleaning Step -III
# Cleaning Variables with too many NA values. 
# I have considered a threshold of 50% of NA values to remove that variable.  

trainingTemp = myTraining #creating another subset to iterate in loop
for(i in 1:length(myTraining)) 
  { 
  #for every column in the training dataset
  if( sum( is.na( myTraining[, i] ) )/nrow(myTraining) > .5 ) 
    { 
    #if no. of NA values > 50% of total observations
    for(j in 1:length(trainingTemp)) 
      {
      if( length( grep(names(myTraining[i]), names(trainingTemp)[j]) ) ==1)  
        { 
        #if the columns are the same:
        trainingTemp = trainingTemp[ , -j] 
        #Remove that column
      }   
    } 
  }
}
#To check the new dimension of our observations
dim(trainingTemp)

#Seting back to our set:
myTraining = trainingTemp
rm(trainingTemp)
```
Now we have to apply the same cleaning Steps for the testing data to have a sync with the testing and the training during the application of ML algorithms 
```{r}
## Cleaning the Testing data sets.

# Here we have to perform all the above cleaning steps on both the myTesting and testing dataset. 
# But for testing set we have to also remove the Classe column which is empty(No values assigned)

clean1 = colnames(myTraining)
clean2 = colnames(myTraining[, -58]) # classe column  = 58 is removed
myTesting = myTesting[clean1]
testing = testing[clean2]

#To check the new dimension of observations
dim(myTesting)

#To check the new dimension of observations
dim(testing)


#In order to ensure proper functioning of Decision Trees and especially RandomForest 
#Algorithm with the Test data set (data set provided), we need to coerce the data 
#into the same type.
for (i in 1:length(testing) ) {
        for(j in 1:length(myTraining)) {
    if( length( grep(names(myTraining[i]), names(testing)[j]) ) ==1)  {
  		class(testing[j]) <- class(myTraining[i])
		}      
	}      
}
```


## Using Decision Trees for prediction
```{r}
modelFitTrees = rpart(classe ~ ., data=myTraining, method="class")
to view the decision tree with fancy run this command:
```{r}
fancyRpartPlot(modelFitTrees)
```
Predicting:
```{r}
predicttrees = predict(modelFitTrees, myTesting, type = "class")


confusionMatrix(predicttrees, myTesting$classe)
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1624   54    4    2    0
##          B   37  943   59   47    0
##          C   13  136  947  156   44
##          D    0    6   16  716  134
##          E    0    0    0   43  904
## 
## Overall Statistics
##                                           
##                Accuracy : 0.8724          
##                  95% CI : (0.8636, 0.8808)
##     No Information Rate : 0.2845          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.8386          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9701   0.8279   0.9230   0.7427   0.8355
## Specificity            0.9858   0.9699   0.9282   0.9683   0.9910
## Pos Pred Value         0.9644   0.8683   0.7307   0.8211   0.9546
## Neg Pred Value         0.9881   0.9592   0.9828   0.9505   0.9640
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2760   0.1602   0.1609   0.1217   0.1536
## Detection Prevalence   0.2862   0.1845   0.2202   0.1482   0.1609
## Balanced Accuracy      0.9779   0.8989   0.9256   0.8555   0.9133
#Overall Statistics
                                          
#               Accuracy : 0.8683          
#                 95% CI : (0.8607, 0.8757)
#    No Information Rate : 0.2845          
#    P-Value [Acc > NIR] : < 2.2e-16       
                                          
#                  Kappa : 0.8335 

```

## Using Random Forests for prediction
```{r}
modelFitRF = randomForest(classe ~. , data=myTraining, type = "class")
```
Predicting:
```{r}
predictRF = predict(modelFitRF, myTesting, type = "class")
```
```{r}
confusionMatrix(predictRF, myTesting$classe)

## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1673    0    0    0    0
##          B    1 1139    2    0    0
##          C    0    0 1022    0    0
##          D    0    0    2  964    2
##          E    0    0    0    0 1080
## 
## Overall Statistics
##                                           
##                Accuracy : 0.989          
##                  95% CI : (0.9976, 0.9995)
##     No Information Rate : 0.2845          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.9985          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9994   1.0000   0.9961   1.0000   0.9982
## Specificity            1.0000   0.9994   1.0000   0.9992   1.0000
## Pos Pred Value         1.0000   0.9974   1.0000   0.9959   1.0000
## Neg Pred Value         0.9998   1.0000   0.9992   1.0000   0.9996
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2843   0.1935   0.1737   0.1638   0.1835
## Detection Prevalence   0.2843   0.1941   0.1737   0.1645   0.1835
## Balanced Accuracy      0.9997   0.9997   0.9981   0.9996   0.9991
#Overall Statistics
                                         
 #              Accuracy : 0.99          
 #                95% CI : (0.998, 0.9996)
 #   No Information Rate : 0.2845         
 #   P-Value [Acc > NIR] : < 2.2e-16      
                                         
 #                 Kappa : 0.9987         
 #Mcnemar's Test P-Value : NA 

```
We observe Random Forests yielded better Results

Generating Files to submit as answers for the Assignment:
Finally, using the provided Test Set:
Note:
#For Decision Tree would be like this, but not going to use it:
#predictTreesTest = predict(modelFitTrees, testing, type = "class")

For Random Forests is, which yielded a much better prediction:

For Random Forests is, which yielded a much better prediction:
```{r}
predictRFtest = predict(modelFitRF, testing, type = "class")
```
Function to generate files with predictions to submit for assignment
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictRFtest)
```

Thanking for giving such an opportunity to apply the theory that we learnt on a real world problem.

Reference:
[1] https://class.coursera.org/predmachlearn-003/human_grading/view/courses/972148/assessments/4/submissions
[2] http://groupware.les.inf.puc-rio.br/har